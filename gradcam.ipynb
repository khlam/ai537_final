{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c323e66-420e-4623-8b26-de7d1ddd6ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import sys\n",
    "from pytorch_grad_cam import GradCAM, EigenCAM\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torchvision.models as models\n",
    "import os\n",
    "\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce156bb4-1a2d-4022-b8a5-df1f7c1b7bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd7302d-6a66-4cac-b03e-f89ee73be1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_png(img_path):\n",
    "    all_png_paths = []\n",
    "    \n",
    "    for dirpath,_,filenames in os.walk(img_path):\n",
    "        for f in filenames:\n",
    "            if f.endswith(\".png\"):\n",
    "                all_png_paths.append(os.path.abspath(os.path.join(dirpath, f)))\n",
    "    \n",
    "    return sorted(all_png_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139e8124-0554-4e35-9dd6-b25b911b81c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_gradcam(img_original, model, layers):\n",
    "    cam = GradCAM(model=model, target_layers=layers, use_cuda=True)\n",
    "    \n",
    "    _toTensor = transforms.ToTensor()\n",
    "    _input = _toTensor(img_original).to(device)\n",
    "    \n",
    "    _input = _input.unsqueeze(0)\n",
    "\n",
    "    grayscale_cam = cam(input_tensor=_input)\n",
    "    \n",
    "    grayscale_cam = grayscale_cam[0, :]\n",
    "\n",
    "    grad_img = show_cam_on_image(np.asarray(img_original) / 255, grayscale_cam, use_rgb=True)\n",
    "    \n",
    "    return Image.fromarray(grad_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55dae26-6bdd-47f5-8935-ed7392626b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_grad_cam(model, layers, inTensor, outPath):\n",
    "    model.eval()\n",
    "\n",
    "    img_grad = do_gradcam(inTensor, model, layers)\n",
    "\n",
    "    img_original = inTensor.resize((300,300))\n",
    "    img_grad = img_grad.resize((300,300))\n",
    "\n",
    "    final_image = np.concatenate((img_original, img_grad), axis=1)\n",
    "\n",
    "    final_image = Image.fromarray(final_image)\n",
    "\n",
    "    final_image.show()\n",
    "    input()\n",
    "\n",
    "    final_image.save(outPath)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064b0680-5e32-4fd1-b2df-9dcf0e49ed9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet18(pretrained=True)\n",
    "\n",
    "layers = [\n",
    "    model.layer1[-1],\n",
    "    model.layer2[-1],\n",
    "    model.layer3[-1],\n",
    "    model.layer4[-1]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f108af1-438e-4e07-9fa3-72c396453a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose( [transforms.ToTensor()])\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "testLoader = torch.utils.data.DataLoader(testset, batch_size=1, shuffle=False, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c45326-7ffe-49b5-80f1-1f4cd2794ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, t_img in enumerate(tqdm.tqdm(testLoader)):\n",
    "    transform_PIL = transforms.ToPILImage()\n",
    "    do_grad_cam(model, layers, transform_PIL(t_img[0][0]), \"./output/\" + str(i) + \".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e3debf-dd74-4260-b65c-e8e316049e83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
